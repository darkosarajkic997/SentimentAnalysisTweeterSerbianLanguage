{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.1 64-bit",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1e3b93fe7ff4eefec2af1a27ca518404a0f894a878f1a79cd53d09793530307f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string  \n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=pd.read_excel(\"ExcelDocs\\\\SerbianTweetsDataSetCorrectedLabels.xlsx\",index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove RT, #, @, numbers and new lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=re.sub(r'RT',' ',text)\n",
    "    text=re.sub(r'(@[A-Za-z0-9!\"#$%&\\'()*+,-./:;<=>?@[\\\\\\]^_`{|}~]+)',' ',text)\n",
    "    text=re.sub(r'#',' ',text)\n",
    "    text=re.sub(r'\\w*\\d\\w*',' ',text)\n",
    "    text=re.sub(r'(http|https)\\S+', ' ', text)\n",
    "    text=re.sub(r'\\n',' ',text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "clean1=lambda x:clean_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets=tweets\n",
    "clean_tweets['Text']=clean_tweets['Text'].map(clean1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojis and emoticons to word conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMO:\n",
    "        text = text.replace(emot, (\" _emo_\"+\"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split())+\" \"))\n",
    "    text=re.sub('_emo_Confusion','',text)\n",
    "    return text\n",
    "\n",
    "\n",
    "emoji=lambda x:convert_emojis(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', (\" _emo_\"+\"_\".join(EMOTICONS[emot].replace(\",\",\"\").split())+\" \"), text)\n",
    "    text=re.sub('_emo_Confusion','',text)\n",
    "    return text\n",
    "\n",
    "emoticons=lambda x:convert_emoticons(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets['Text']=clean_tweets['Text'].map(emoji)\n",
    "clean_tweets['Text']=clean_tweets['Text'].map(emoticons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unnecessary characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\\u0107-ć \\u010D-č \\u0111-đ \\u0161-š \\u017E-ž \n",
    "def remove_unnecessary_characters(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(r\"[^a-z\\u0107\\u010D\\u0111\\u0161\\u017E .,!?_']\",' ',text, re.UNICODE)\n",
    "    return text\n",
    "\n",
    "unnecessary_characters=lambda x:remove_unnecessary_characters(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_successive_characters(text):\n",
    "    text=re.sub(r'((.)\\2{2,})',r'\\2',text)\n",
    "    text=re.sub(r\"([.,!?'])\", r' \\1 ', text)\n",
    "    return text\n",
    "\n",
    "remove_successive=lambda x:remove_successive_characters(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets['Text']=clean_tweets['Text'].map(unnecessary_characters)\n",
    "clean_tweets['Text']=clean_tweets['Text'].map(remove_successive)"
   ]
  },
  {
   "source": [
    "# Remove empty tweets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets['Text'].replace([' ',''], np.nan, inplace=True)\n",
    "clean_tweets.dropna(subset=['Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets.to_excel(\"ExcelDocs\\\\Processed_Tweets.xlsx\")\n",
    "clean_tweets.to_pickle(\"PickleDataframes\\\\Processed_Tweets.pkl\")"
   ]
  }
 ]
}