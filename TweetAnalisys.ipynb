{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.1 64-bit",
   "display_name": "Python 3.8.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1e3b93fe7ff4eefec2af1a27ca518404a0f894a878f1a79cd53d09793530307f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=pd.read_pickle('PickleDataframes\\\\TweetsWithoutSW.pkl')\n",
    "tweets=tweets.drop('FilteredText',axis=1)\n",
    "tweets=tweets.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec = CountVectorizer(ngram_range=(1,1), binary=True)\n",
    "tweetsDF=pd.DataFrame(countvec.fit_transform(tweets['without_sw']).toarray().astype('int8'), columns=countvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 20194 entries, 0 to 20193\nColumns: 6416 entries, _emo_cat_face_with_tears_of_joy to Å¾vaka\ndtypes: int8(6416)\nmemory usage: 123.6 MB\n"
    }
   ],
   "source": [
    "tweetsDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF['Label']=tweets['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_negative_words_array():\n",
    "    negative_words=[]\n",
    "    with open('TxtDocs\\\\NegativeSentimentWords.txt','r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                negative_words.append(word)\n",
    "\n",
    "    with open('TxtDocs\\\\PositiveSentimentWords.txt','r',encoding='utf8') as f:\n",
    "       for line in f:\n",
    "          for word in line.split():\n",
    "             negative_words.append(''.join([word,'_NEG']))\n",
    "    return negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_positive_words_array():\n",
    "    positive_words=[]\n",
    "    with open('TxtDocs\\\\PositiveSentimentWords.txt','r',encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                positive_words.append(word)\n",
    "\n",
    "    with open('TxtDocs\\\\NegativeSentimentWords.txt','r',encoding='utf8') as f:\n",
    "       for line in f:\n",
    "          for word in line.split():\n",
    "             positive_words.append(''.join([word,'_NEG']))\n",
    "    return positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_words_from_dataset():\n",
    "    negative_words=[]\n",
    "    with open('TxtDocs\\\\NegativeWordsFromDataset.txt','r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                negative_words.append(word)\n",
    "    return negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_words_from_dataset():\n",
    "    positive_words=[]\n",
    "    with open('TxtDocs\\\\PositiveWordsFromDataset.txt','r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            for word in line.split():\n",
    "                positive_words.append(word)\n",
    "    return positive_words"
   ]
  },
  {
   "source": [
    "#"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words(word_array,text):\n",
    "    res=0\n",
    "    for word in text.split():\n",
    "        if word in word_array:\n",
    "            res+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_negation(text):\n",
    "    res=0\n",
    "    i=0\n",
    "    for word in text.split():\n",
    "        i+=1       \n",
    "        if word.endswith('_NEG'):\n",
    "            res+=1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_emo(text):\n",
    "    res=0\n",
    "    i=0\n",
    "    for word in text.split():\n",
    "        i+=1\n",
    "        if word.startswith('_emo_'):\n",
    "            res+=1\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_from_dataset=positive_words_from_dataset()\n",
    "negative_from_dataset=negative_words_from_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words=create_positive_words_array()\n",
    "negative_words=create_negative_words_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF['positive_sentiment']=tweets.apply(lambda row:find_words(positive_words,row['without_sw']),axis=1)\n",
    "tweetsDF['negative_sentiment']=tweets.apply(lambda row:find_words(negative_words,row['without_sw']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF['number_of_negations']=tweets.apply(lambda row:count_negation(row['without_sw']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF['positive_fromDS']=tweets.apply(lambda row:find_words(positive_from_dataset, row['without_sw']),axis=1)\n",
    "tweetsDF['negative_fromDS']=tweets.apply(lambda row:find_words(negative_from_dataset, row['without_sw']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_emo=['_emo_cat_face_with_tears_of_joy','_emo_clapping_hands','_emo_face_blowing_a_kiss','_emo_face_with_stuck','_emo_hace_or_smace_smiley','_emo_hace_smace_smiley', '_emo_happy_face_or_smiley', '_emo_happy_face_smiley', '_emo_heart_suit', '_emo_kiss', '_emo_laughing_big_grin_or_laugh_with_glasses', '_emo_party_popper', '_emo_red_heart','_emo_smiling_face_with_open_mouth_','_emo_tongue_sticking_out_cheeky_playful_or_blowing_a_raspberry','_emo_wink_or_smirk','_emo_woman_dancing']\n",
    "negative_emo=['_emo_crying','_emo_embarrassed_or_blushing','_emo_face_screaming_in_fear','_emo_frown_sad_andry_or_pouting','_emo_sadness','_emo_skeptical_annoyed_undecided_uneasy_or_hesitant','_emo_surpised','_emo_surprise',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF['positive_emo']=tweets.apply(lambda row:find_words(positive_emo, row['without_sw']),axis=1)\n",
    "tweetsDF['negative_emo']=tweets.apply(lambda row:find_words(negative_emo, row['without_sw']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_char(char,text):\n",
    "    tokens=text.split()\n",
    "    res=0\n",
    "    for token in tokens:\n",
    "        if token==char:\n",
    "            res+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF['question_mark_count']=tweets.apply(lambda row:find_char('?', row['without_sw']),axis=1)\n",
    "tweetsDF['exclamation_mark_count']=tweets.apply(lambda row:find_char('!', row['without_sw']),axis=1)"
   ]
  },
  {
   "source": [
    "#"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_fml2cl=tweetsDF.loc[tweetsDF['Label']!='Neutral']"
   ]
  },
  {
   "source": [
    "# Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix,classification_report,balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationFunction(classificator,X_train,X_test,y_train,y_test):\n",
    "    classificator.fit(X_train,y_train)\n",
    "    prediction=classificator.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test,prediction))\n",
    "    print(confusion_matrix(y_test,prediction))\n",
    "   \n",
    "    return accuracy_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(tweetsDF['Label'])\n",
    "tweetsDF.HandLabel=le.transform(tweetsDF['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(tweet_fml2cl['Label'])\n",
    "tweet_fml2cl.HandLabel=le.transform(tweet_fml2cl['Label'])"
   ]
  },
  {
   "source": [
    "### X y is used for dataset with 3 classes positive, negative and neutral and X2 y2 for dataset with only positive and negative classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tweetsDF.drop('Label',axis=1)\n",
    "y=tweetsDF['Label']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=3,stratify=y)\n",
    "\n",
    "X_train=pd.DataFrame(X_train,columns=list(X))\n",
    "X_test=pd.DataFrame(X_test,columns=list(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2=tweet_fml2cl.drop('Label',axis=1)\n",
    "y2=tweet_fml2cl['Label']\n",
    "\n",
    "X2_train,X2_test,y2_train,y2_test=train_test_split(X2,y2,test_size=0.25,random_state=3,stratify=y2)\n",
    "\n",
    "X2_train=pd.DataFrame(X2_train,columns=list(X2))\n",
    "X2_test=pd.DataFrame(X2_test,columns=list(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "80"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "del [[tweetsDF,tweet_fml2cl]]\n",
    "gc.collect()"
   ]
  },
  {
   "source": [
    "## MultinomialNB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n    Negative       0.63      0.65      0.64      1772\n     Neutral       0.58      0.59      0.58      2193\n    Positive       0.58      0.53      0.55      1084\n\n    accuracy                           0.60      5049\n   macro avg       0.60      0.59      0.59      5049\nweighted avg       0.60      0.60      0.60      5049\n\n[[1156  533   83]\n [ 572 1296  325]\n [ 102  411  571]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.598732422261834"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "ClassificationFunction(MultinomialNB(alpha=7.3),X_train,X_test,y_train,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n    Negative       0.83      0.90      0.86      1772\n    Positive       0.81      0.70      0.75      1084\n\n    accuracy                           0.82      2856\n   macro avg       0.82      0.80      0.81      2856\nweighted avg       0.82      0.82      0.82      2856\n\n[[1596  176]\n [ 328  756]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8235294117647058"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "ClassificationFunction(MultinomialNB(alpha=7),X2_train,X2_test,y2_train,y2_test) "
   ]
  },
  {
   "source": [
    "## GradientBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    Negative       0.64      0.63      0.63      1772\n     Neutral       0.56      0.61      0.58      2193\n    Positive       0.63      0.54      0.58      1084\n\n    accuracy                           0.60      5049\n   macro avg       0.61      0.59      0.60      5049\nweighted avg       0.60      0.60      0.60      5049\n\n[[1108  599   65]\n [ 583 1335  275]\n [  46  451  587]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6001188354129531"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "ClassificationFunction(GradientBoostingClassifier(n_estimators=100),X_train,X_test,y_train,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    Negative       0.87      0.90      0.88      1772\n    Positive       0.83      0.77      0.80      1084\n\n    accuracy                           0.85      2856\n   macro avg       0.85      0.84      0.84      2856\nweighted avg       0.85      0.85      0.85      2856\n\n[[1598  174]\n [ 246  838]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8529411764705882"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "ClassificationFunction(GradientBoostingClassifier(random_state=0),X2_train,X2_test,y2_train,y2_test) "
   ]
  },
  {
   "source": [
    "## XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    Negative       0.69      0.58      0.63      1772\n     Neutral       0.58      0.71      0.64      2193\n    Positive       0.64      0.51      0.57      1084\n\n    accuracy                           0.62      5049\n   macro avg       0.64      0.60      0.61      5049\nweighted avg       0.63      0.62      0.62      5049\n\n[[1022  683   67]\n [ 379 1567  247]\n [  75  457  552]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6221033868092691"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "ClassificationFunction(XGBClassifier(),X_train,X_test,y_train,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    Negative       0.87      0.90      0.88      1772\n    Positive       0.82      0.78      0.80      1084\n\n    accuracy                           0.85      2856\n   macro avg       0.85      0.84      0.84      2856\nweighted avg       0.85      0.85      0.85      2856\n\n[[1592  180]\n [ 243  841]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.851890756302521"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "ClassificationFunction(XGBClassifier(),X2_train,X2_test,y2_train,y2_test)"
   ]
  },
  {
   "source": [
    "## SVC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n    Negative       0.70      0.57      0.63      1772\n     Neutral       0.58      0.75      0.65      2193\n    Positive       0.68      0.46      0.55      1084\n\n    accuracy                           0.63      5049\n   macro avg       0.65      0.60      0.61      5049\nweighted avg       0.64      0.63      0.62      5049\n\n[[1016  704   52]\n [ 359 1647  187]\n [  85  499  500]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6264606852842147"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "ClassificationFunction(SVC(C=1),X_train,X_test,y_train,y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n    Negative       0.85      0.90      0.88      1772\n    Positive       0.82      0.74      0.78      1084\n\n    accuracy                           0.84      2856\n   macro avg       0.84      0.82      0.83      2856\nweighted avg       0.84      0.84      0.84      2856\n\n[[1597  175]\n [ 278  806]]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8413865546218487"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "ClassificationFunction(SVC(C=2),X2_train,X2_test,y2_train,y2_test) "
   ]
  },
  {
   "source": [
    "## Mean score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanScorer(classifier,X,y, acc):\n",
    "    cvs=cross_val_score(classifier,X,y, cv=5,scoring=acc, error_score='raise')\n",
    "    print(cvs)\n",
    "    return cvs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.6135182  0.58603615 0.63010646 0.63035405 0.62456662]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6169162944598731"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "MeanScorer(SVC(C=1), X, y, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.82669584 0.8083151  0.84507659 0.84726477 0.84325744]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8341219481350619"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "MeanScorer(SVC(C=2), X2, y2, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}